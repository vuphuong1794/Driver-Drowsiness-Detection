{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f96ade-afeb-473d-8b8a-eb4924b8833b",
   "metadata": {},
   "source": [
    "## 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd479e0-fa04-4a0f-a528-c1e2b906c53c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b3df6-135d-4edd-b750-c0761e924e31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a2d32-911c-4c9a-8998-ecb13c3e6caf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cd yolov5 & pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e72b79-04c8-44de-8032-b7ff836f336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ab648-aad7-4120-a3ab-ce56105df360",
   "metadata": {},
   "source": [
    "## 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95c1bd-6b72-4fd3-a628-69c26d358c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed3905-553b-4b4d-863a-bd5dd76cc64e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327476a-2098-44a8-ba3c-6d9a14808b2a",
   "metadata": {},
   "source": [
    "## 3. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce3981-7070-45b6-a190-bcec573a4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.its.ucla.edu/wp-content/uploads/sites/6/2018/01/los-angeles-1396606_960_720.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288973f-0f66-4599-b7cc-25e3087ea4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    img = Image.open(BytesIO(response.content))  # Chuyển thành PIL.Image\n",
    "else:\n",
    "    raise Exception(\"Không thể tải ảnh từ URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8178b15-9ab2-4b50-b9ea-26142b307fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2af7c6-ffd5-43eb-9d10-d9889e828763",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969668b",
   "metadata": {},
   "source": [
    "## 4. Real Time Dectections and Object Dectection using Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7b73d-536e-4fdd-8733-9d3145cd7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # truy cap webcam\n",
    "while cap.isOpened(): # kiem tram webcam mo hay dong\n",
    "    ret, frame = cap.read()\n",
    "    results = model(frame)\n",
    "    cv2.imshow('PHƯN', np.squeeze(results.render())) # mang hinh hien thi, \"PHƯN\" la ten\n",
    "    if cv2.waitKey(10) & 0xFF in [ord('\\r'), ord('\\n')]: # nhan phim enter de thoat\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701e4dd",
   "metadata": {},
   "source": [
    "## 5. Train a Custom YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88bf572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid # tao ma dinh danh duy nhat\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PART = os.path.join('data', 'images')\n",
    "labels = ['awake', 'drowsy'] # 2 trang thai tinh tao va bun ngu\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e500ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for label in labels: # vong lap cua 2 trang thai\n",
    "    print('Collecting images for {}'. format(label))\n",
    "    time.sleep(5) \n",
    "    for img_num in range(number_imgs):  # thu thap 20 hinh anh cho moi trang thai\n",
    "        print('Collecting images for {}, images number {}'.format(label, img_num))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PART, label+'.'+str(uuid.uuid1())+'.jpg') # dat ten cho anh thu duoc\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('Image collection', frame)\n",
    "        time.sleep(2)\n",
    "        if cv2.waitKey(10) & 0xFF in [ord('\\r'), ord('\\n')]: # nhan phim enter de thoat\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HumanSignal/labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee943c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyqt5 lxml --upgrade\n",
    "!cd labelImg && pyrcc5 -o libs/resource.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71143ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command 'git fetch origin' returned non-zero exit status 128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=2, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "fatal: full write to remote helper failed: Broken pipe\n",
      "fatal: cannot change to 'D:\\HK2': No such file or directory\n",
      "YOLOv5  2025-3-13 Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\data\\labels.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|██████████| 40/40 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\data\\labels.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|██████████| 40/40 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\data\\labels.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|██████████| 40/40 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\data\\labels.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|██████████| 40/40 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.60 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp7\\labels.jpg... \n",
      "d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp7\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/4     0.963G     0.1111    0.01679    0.07699         38        320:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        0/4     0.963G     0.1111    0.01679    0.07699         38        320:  33%|███▎      | 1/3 [00:00<00:01,  1.12it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/4     0.975G     0.1097    0.01647    0.07577         30        320:  33%|███▎      | 1/3 [00:01<00:01,  1.12it/s]\n",
      "        0/4     0.975G     0.1097    0.01647    0.07577         30        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/4      1.01G     0.1118    0.01554    0.07577         15        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]\n",
      "        0/4      1.01G     0.1118    0.01554    0.07577         15        320: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "        0/4      1.01G     0.1118    0.01554    0.07577         15        320: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 1/2 [00:00<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  2.80it/s]\n",
      "                   all         40         40          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/4      1.13G     0.1111    0.01658    0.07592         35        320:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        1/4      1.13G     0.1111    0.01658    0.07592         35        320:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/4      1.13G      0.107     0.0153    0.07679         25        320:  33%|███▎      | 1/3 [00:01<00:01,  1.80it/s]\n",
      "        1/4      1.13G      0.107     0.0153    0.07679         25        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/4      1.15G     0.1061     0.0149    0.07603         13        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s]\n",
      "        1/4      1.15G     0.1061     0.0149    0.07603         13        320: 100%|██████████| 3/3 [00:01<00:00,  2.24it/s]\n",
      "        1/4      1.15G     0.1061     0.0149    0.07603         13        320: 100%|██████████| 3/3 [00:01<00:00,  2.10it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 1/2 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
      "                   all         40         40    0.00133       0.05   0.000811   8.11e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        2/4      1.15G      0.106    0.01885    0.07551         36        320:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        2/4      1.15G      0.106    0.01885    0.07551         36        320:  33%|███▎      | 1/3 [00:00<00:01,  1.73it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        2/4      1.15G     0.1045    0.01807    0.07348         32        320:  33%|███▎      | 1/3 [00:01<00:01,  1.73it/s]\n",
      "        2/4      1.15G     0.1045    0.01807    0.07348         32        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        2/4      1.15G     0.1037    0.01869    0.07363         18        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s]\n",
      "        2/4      1.15G     0.1037    0.01869    0.07363         18        320: 100%|██████████| 3/3 [00:01<00:00,  2.20it/s]\n",
      "        2/4      1.15G     0.1037    0.01869    0.07363         18        320: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 1/2 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n",
      "                   all         40         40    0.00126       0.05   0.000776   7.76e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        3/4      1.15G     0.1048    0.01895    0.07278         36        320:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        3/4      1.15G     0.1048    0.01895    0.07278         36        320:  33%|███▎      | 1/3 [00:00<00:01,  1.81it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        3/4      1.15G     0.1022    0.02079    0.07195         40        320:  33%|███▎      | 1/3 [00:01<00:01,  1.81it/s]\n",
      "        3/4      1.15G     0.1022    0.02079    0.07195         40        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        3/4      1.16G     0.1002    0.02032    0.07166         16        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s]\n",
      "        3/4      1.16G     0.1002    0.02032    0.07166         16        320: 100%|██████████| 3/3 [00:01<00:00,  2.23it/s]\n",
      "        3/4      1.16G     0.1002    0.02032    0.07166         16        320: 100%|██████████| 3/3 [00:01<00:00,  2.10it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 1/2 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
      "                   all         40         40    0.00123       0.05    0.00077    7.7e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        4/4      1.16G    0.09587    0.02658    0.07153         44        320:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        4/4      1.16G    0.09587    0.02658    0.07153         44        320:  33%|███▎      | 1/3 [00:00<00:01,  1.76it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        4/4      1.16G    0.09692    0.02405     0.0714         36        320:  33%|███▎      | 1/3 [00:01<00:01,  1.76it/s]\n",
      "        4/4      1.16G    0.09692    0.02405     0.0714         36        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s]d:\\HK2 2024-2025\\HTGTTM\\Driver-Drowsiness-Detection\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        4/4      1.18G    0.09375    0.02352    0.07077         17        320:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s]\n",
      "        4/4      1.18G    0.09375    0.02352    0.07077         17        320: 100%|██████████| 3/3 [00:01<00:00,  2.22it/s]\n",
      "        4/4      1.18G    0.09375    0.02352    0.07077         17        320: 100%|██████████| 3/3 [00:01<00:00,  2.08it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 1/2 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
      "                   all         40         40    0.00118       0.05   0.000738   7.38e-05\n",
      "\n",
      "5 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs\\train\\exp7\\weights\\last.pt, 14.4MB\n",
      "Optimizer stripped from runs\\train\\exp7\\weights\\best.pt, 14.4MB\n",
      "\n",
      "Validating runs\\train\\exp7\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7055974 parameters, 0 gradients, 15.9 GFLOPs\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 1/2 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:00<00:00,  2.74it/s]\n",
      "                   all         40         40    0.00134       0.05   0.000813   8.13e-05\n",
      "                 awake         40         20          0          0          0          0\n",
      "                drowsy         40         20    0.00267        0.1    0.00163   0.000163\n",
      "Results saved to \u001b[1mruns\\train\\exp7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 && python train.py --img 320 --batch 16 --epochs 5 --data dataset.yaml --weights yolov5s.pt --worker 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
